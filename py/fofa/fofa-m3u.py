import os, re, socket, datetime

# --- é…ç½®ä¿æŒä¸å˜ ---
IP_DIR = "py/fofa/ip"
RTP_DIR = "py/fofa/rtp"
OUTPUT_TXT = "py/fofa/IPTV.txt"
OUTPUT_M3U = "py/fofa/IPTV.m3u"
M3U_DIR = "py/fofa/m3u_groups"
LOGO_BASE = "https://gcore.jsdelivr.net/gh/kenye201/TVlog/img/"
CORE_SAT = ["æ¹–å—å«è§†", "ä¸œæ–¹å«è§†", "æµ™æ±Ÿå«è§†", "æ±Ÿè‹å«è§†", "åŒ—äº¬å«è§†", "æ¹–åŒ—å«è§†", "æ·±åœ³å«è§†"]

def verify_url(url):
    try:
        match = re.search(r'http://([^:/]+):?(\d+)?/', url)
        if not match: return False
        host, port = match.group(1), int(match.group(2)) if match.group(2) else 80
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.settimeout(1.5)
            return s.connect_ex((host, port)) == 0
    except: return False

def clean_name(name):
    clean = re.sub(r'[\(\[\uff08].*?[\)\]\uff09]', '', name).upper().replace(" ", "").replace("-", "")
    # ä¿æŒ HD/4K æ ‡è®°ç”¨äºåç»­æ’åºåˆ¤æ–­ï¼Œä½†åœ¨æœ€ç»ˆæ˜¾ç¤ºå‰å¯æ ¹æ®éœ€è¦å¤„ç†
    m = re.search(r'CCTV(\d+)', clean)
    if m:
        num = m.group(1)
        if "5+" in clean: return "CCTV5+"
        return f"CCTV{num}"
    return clean

def get_sort_weight(name):
    """
    è®¡ç®—é¢‘é“æ’åºæƒé‡ï¼Œåˆ†å€¼è¶Šå°è¶Šé å‰
    1. å¤®è§†æ•°å­— (1-17): 100 + æ•°å­—
    2. 4Ké¢‘é“: 200
    3. æ™®é€šå«è§† (CORE_SATä¼˜å…ˆ): 300
    4. åœ°æ–¹å° (åœ°åå¼€å¤´): 400
    5. å…¶ä»–é¢‘é“: 500
    6. å¤®è§†éæ•°å­— (å‰§åœºç­‰): 600
    """
    # 1. å¤®è§†æ•°å­—ç±»
    cctv_num = re.search(r'CCTV(\d+)', name)
    if cctv_num:
        return 100 + int(cctv_num.group(1))
    if name == "CCTV5+":
        return 118 # æ’åœ¨17ä¹‹å
    
    # 2. 4K å«è§†
    if "4K" in name:
        return 200

    # 3. å«è§†ç±»
    if "å«è§†" in name:
        if any(s in name for s in CORE_SAT):
            return 300 # æ ¸å¿ƒå«è§†ä¼˜å…ˆ
        return 310 # å…¶ä»–å«è§†

    # 4. å¤®è§†éæ•°å­—å‰§åœºç±» (åˆ¤å®šè§„åˆ™ï¼šåŒ…å«å‰§åœºæˆ–ç‰¹å®šå¤®è§†åç§°)
    if any(x in name for x in ["å‰§åœº", "å…µå™¨", "é£äº‘", "å¥³æ€§", "ä¸–ç•Œåœ°ç†", "å¤®è§†"]):
        return 600

    # 5. åœ°æ–¹å°åˆ¤å®š (åˆ¤æ–­æ ‡å‡†ï¼šä»¥çœä»½/åœ°åå¼€å¤´ä¸”åŒ…å«å¤šä¸ªå­é¢‘é“)
    # è¿™é‡Œé€šè¿‡æ£€æŸ¥åå­—é•¿åº¦å’Œå¸¸è§åœ°åç®€å•åˆ¤å®š
    provinces = ["å±±ä¸œ", "æ±Ÿè‹", "æµ™æ±Ÿ", "å¹¿ä¸œ", "æ¹–å—", "æ¹–åŒ—", "æ²³å—", "æ²³åŒ—", "å®‰å¾½", "ç¦å»º", "æ±Ÿè¥¿", "è¾½å®", "å‰æ—", "é»‘é¾™æ±Ÿ", "å±±è¥¿", "é™•è¥¿", "ç”˜è‚ƒ", "é’æµ·", "å››å·", "è´µå·", "äº‘å—", "æµ·å—", "å°æ¹¾", "åŒ—äº¬", "å¤©æ´¥", "ä¸Šæµ·", "é‡åº†", "å¹¿è¥¿", "å†…è’™å¤", "è¥¿è—", "å®å¤", "æ–°ç–†"]
    if any(name.startswith(p) for p in provinces):
        return 400

    # 6. å…¶ä»–
    return 500

def run_workflow():
    if not os.path.exists(IP_DIR): return
    if not os.path.exists(M3U_DIR): os.makedirs(M3U_DIR)
    
    all_valid_data = []
    ip_files = sorted(os.listdir(IP_DIR))
    
    for f_name in ip_files:
        if not f_name.endswith(".txt"): continue
        isp_base = f_name.replace(".txt", "").replace("å¸‚", "")
        rtp_path = os.path.join(RTP_DIR, f_name)
        if not os.path.exists(rtp_path): continue

        with open(os.path.join(IP_DIR, f_name), 'r', encoding='utf-8') as f: ips = f.read().splitlines()
        with open(rtp_path, 'r', encoding='utf-8') as f: rtps = [l.strip() for l in f if "," in l]
        
        if not ips or not rtps: continue

        valid_count = 1
        for ip in ips:
            if not ip.strip(): continue
            test_url = f"http://{ip}/{'rtp' if 'rtp' in rtps[0] else 'udp'}/{rtps[0].split('://')[-1]}"
            print(f"ğŸ“¡ æ¢æµ‹ [{isp_base}] {ip} ... ", end="", flush=True)
            
            if verify_url(test_url):
                print("âœ…")
                group_name = f"{isp_base}{valid_count}"
                for r_line in rtps:
                    name, r_url = r_line.split(',', 1)
                    c_name = clean_name(name)
                    all_valid_data.append({
                        "isp": isp_base, 
                        "group": group_name, 
                        "name": c_name, 
                        "url": f"http://{ip}/{'rtp' if 'rtp' in r_url else 'udp'}/{r_url.split('://')[-1]}",
                        "weight": get_sort_weight(c_name)
                    })
                valid_count += 1
            else: print("âŒ")

    if not all_valid_data: return
    
    # --- æ ¸å¿ƒæ’åºé€»è¾‘æ”¹è¿› ---
    # æ’åºä¼˜å…ˆçº§ï¼šè¿è¥å•† -> ç»„ -> æƒé‡ -> åå­—
    all_valid_data.sort(key=lambda x: (x['isp'], x['group'], x['weight'], x['name']))
    
    beijing_now = (datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(hours=8)).strftime("%Y-%m-%d %H:%M:%S")

    # å†™å…¥æ–‡ä»¶é€»è¾‘
    with open(OUTPUT_TXT, 'w', encoding='utf-8') as f:
        f.write(f"æ›´æ–°æ—¶é—´: {beijing_now}\n")
        last_group = None
        for it in all_valid_data:
            if it['group'] != last_group:
                f.write(f"\n{it['group']},#genre#\n")
                last_group = it['group']
            f.write(f"{it['name']},{it['url']}\n")

    # æ±‡æ€» M3U
    with open(OUTPUT_M3U, 'w', encoding='utf-8') as f:
        f.write(f'#EXTM3U x-tvg-url="http://epg.51zmt.top:8000/e.xml" refresh="{beijing_now}"\n')
        for it in all_valid_data:
            logo = f"{LOGO_BASE}{it['name']}.png"
            f.write(f'#EXTINF:-1 tvg-logo="{logo}" group-title="{it["group"]}",{it["name"]}\n{it["url"]}\n')

    print(f"\nâœ¨ å¤„ç†å®Œæˆï¼Œå·²æŒ‰é¢‘é“ç±»å‹æ·±åº¦æ’ç‰ˆã€‚")

if __name__ == "__main__":
    run_workflow()
